# Sistema de ComparaciÃ³n de Embeddings

Sistema completo para comparar diferentes modelos de embeddings y generar reportes detallados.

## ğŸš€ CaracterÃ­sticas

- **MÃºltiples Modelos**: Compara MiniLM-L6-v2, MPNet-base-v2 y Azure OpenAI Ada-002
- **NormalizaciÃ³n de Texto**: OpciÃ³n para convertir texto a minÃºsculas antes de generar embeddings
- **Reportes AutomÃ¡ticos**: Genera reportes en JSON, CSV y texto
- **OrganizaciÃ³n por Sesiones**: Cada ejecuciÃ³n se guarda en una carpeta con fecha y hora
- **GestiÃ³n de Sesiones**: Script para navegar y comparar sesiones anteriores
- **Datos Externos**: Carga work orders y queries desde archivos JSON
- **ConfiguraciÃ³n Flexible**: Ajusta thresholds y parÃ¡metros via archivos de configuraciÃ³n
- **AnÃ¡lisis Detallado**: Rankings, similitudes y mÃ©tricas de performance

## ğŸ“ Estructura del Proyecto

```
embedding-comparison/
â”œâ”€â”€ emb_test.py              # Script principal
â”œâ”€â”€ data_loader.py           # Cargador de datos externos
â”œâ”€â”€ session_manager.py       # Gestor de sesiones
â”œâ”€â”€ example_usage.py         # Ejemplos de uso
â”œâ”€â”€ data/                    # Directorio de datos
â”‚   â”œâ”€â”€ work_orders.json     # Work orders de ejemplo
â”‚   â”œâ”€â”€ test_queries.json    # Queries de prueba
â”‚   â””â”€â”€ config.json          # ConfiguraciÃ³n del sistema
â”œâ”€â”€ embedding_reports/       # Reportes generados
â”‚   â”œâ”€â”€ sessions_index.txt   # Ãndice de todas las sesiones
â”‚   â””â”€â”€ embedding_report_27-7-2025-21:08/  # SesiÃ³n especÃ­fica
â”‚       â”œâ”€â”€ embedding_comparison_20250727_210800.json
â”‚       â”œâ”€â”€ similarity_scores_20250727_210800.csv
â”‚       â”œâ”€â”€ rankings_20250727_210800.csv
â”‚       â””â”€â”€ summary_20250727_210800.txt
â””â”€â”€ README.md               # Este archivo
```

## ğŸ› ï¸ InstalaciÃ³n

1. **Instalar dependencias**:
   ```bash
   uv add openai sentence-transformers scikit-learn
   ```

2. **Ejecutar con entorno virtual**:
   ```bash
   uv run python emb_test.py
   ```

## ğŸ“Š Uso BÃ¡sico

### 1. Usar Datos por Defecto
```bash
uv run python emb_test.py
```

### 2. Personalizar Datos
Edita los archivos en `data/`:

**`data/work_orders.json`**:
```json
[
  "REPLACED BRAKE PADS ON MAIN LANDING GEAR",
  "FUEL PUMP PRESSURE LOW - INSPECTION REQUIRED",
  "AVIONICS DISPLAY SHOWING ERROR CODES"
]
```

**`data/test_queries.json`**:
```json
[
  "brake system maintenance",
  "fuel pump pressure",
  "avionics display error"
]
```

### 3. Modificar ConfiguraciÃ³n
**`data/config.json`**:
```json
{
  "confidence_thresholds": {
    "minilm": {"high": 0.70, "medium": 0.50},
    "mpnet": {"high": 0.75, "medium": 0.55}
  },
  "output_settings": {
    "default_output_dir": "my_reports"
  },
  "text_processing": {
    "normalize_to_lowercase": true,
    "description": "Convierte todo el texto a minÃºsculas antes de generar embeddings"
  }
}
```

### 4. ConfiguraciÃ³n de NormalizaciÃ³n de Texto

El sistema incluye una opciÃ³n para normalizar el texto a minÃºsculas antes de generar embeddings, lo que puede mejorar la consistencia de los resultados.

**ConfiguraciÃ³n con normalizaciÃ³n** (`data/config.json`):
```json
{
  "text_processing": {
    "normalize_to_lowercase": true,
    "description": "Convierte todo el texto a minÃºsculas antes de generar embeddings"
  }
}
```

**ConfiguraciÃ³n sin normalizaciÃ³n** (`data/config_no_normalize.json`):
```json
{
  "text_processing": {
    "normalize_to_lowercase": false,
    "description": "Mantiene la capitalizaciÃ³n original del texto"
  }
}
```

**Probar diferencias de normalizaciÃ³n**:
```bash
uv run python test_normalization.py
```

## ğŸ”§ Ejemplos Avanzados

### Ejecutar Ejemplos de Uso
```bash
uv run python example_usage.py
```

### Usar Datos Personalizados
```python
from data_loader import DataLoader
from emb_test import EmbeddingComparator

# Cargar datos personalizados
data_loader = DataLoader()
work_orders = data_loader.load_work_orders("my_work_orders.json")
queries = data_loader.load_test_queries("my_queries.json")
config = data_loader.load_config("my_config.json")

# Ejecutar comparaciÃ³n
comparator = EmbeddingComparator(output_dir="my_reports", config=config)
for query in queries:
    comparator.compare_models(query, work_orders)
comparator.generate_reports()
```

### Procesamiento por LotÃ©s
```python
# Procesar mÃºltiples datasets
datasets = {
    "aviation": {"work_orders": [...], "queries": [...]},
    "automotive": {"work_orders": [...], "queries": [...]}
}

for name, data in datasets.items():
    comparator = EmbeddingComparator(output_dir=f"{name}_reports")
    for query in data["queries"]:
        comparator.compare_models(query, data["work_orders"])
    comparator.generate_reports()
```

## ğŸ“ˆ Reportes Generados

### 1. **JSON Completo** (`embedding_comparison_TIMESTAMP.json`)
- Todos los datos estructurados
- Ideal para anÃ¡lisis programÃ¡tico

### 2. **CSV Detallado** (`similarity_scores_TIMESTAMP.csv`)
- Cada fila = combinaciÃ³n query-documento-modelo
- Incluye scores, confianza y timestamps

### 3. **CSV de Rankings** (`rankings_TIMESTAMP.csv`)
- Rankings ordenados por similitud
- FÃ¡cil importaciÃ³n en Excel/Sheets

### 4. **Resumen Ejecutivo** (`summary_TIMESTAMP.txt`)
- EstadÃ­sticas agregadas por modelo
- MÃ©tricas de performance
- Recomendaciones

## âš™ï¸ ConfiguraciÃ³n

### Modelos Disponibles
- **MiniLM-L6-v2**: 384 dimensiones, rÃ¡pido
- **MPNet-base-v2**: 768 dimensiones, balanceado
- **Azure OpenAI Ada**: 1536 dimensiones, alta calidad

### Thresholds de Confianza
```json
{
  "minilm": {"high": 0.60, "medium": 0.40},
  "mpnet": {"high": 0.65, "medium": 0.45},
  "azure_ada": {"high": 0.70, "medium": 0.50}
}
```

### ConfiguraciÃ³n de Salida
```json
{
  "output_settings": {
    "default_output_dir": "embedding_reports",
    "include_timestamp": true,
    "generate_all_reports": true
  }
}
```

## ğŸ” InterpretaciÃ³n de Resultados

### Niveles de Confianza
- **ğŸŸ¢ Strong Match** (> 0.70): Excelente coincidencia
- **ğŸŸ¡ Good Match** (0.50-0.70): Buena coincidencia
- **ğŸ”´ Weak Match** (< 0.50): Coincidencia dÃ©bil

### ComparaciÃ³n con pgvector
Los scores de similitud son equivalentes a:
```sql
SELECT *, 1 - (embeddings <=> %s::vector) AS similarity
FROM work_orders ORDER BY embeddings <=> %s::vector;
```

## ğŸš€ Casos de Uso

### 1. **AnÃ¡lisis de Work Orders**
- Comparar diferentes modelos para bÃºsqueda semÃ¡ntica
- Evaluar calidad de matches en mantenimiento aeronÃ¡utico

### 2. **OptimizaciÃ³n de Modelos**
- Probar diferentes thresholds de confianza
- Comparar performance vs calidad

### 3. **MigraciÃ³n de Sistemas**
- Validar equivalencia con pgvector
- Calibrar nuevos modelos

## ğŸ“ PersonalizaciÃ³n

### Agregar Nuevos Modelos
1. Edita `data/config.json`
2. Agrega configuraciÃ³n del modelo
3. Actualiza `emb_test.py` si es necesario

### Nuevos Tipos de Datos
1. Crea archivos JSON en `data/`
2. Usa `DataLoader` para cargar
3. Ejecuta comparaciones

### Reportes Personalizados
1. Extiende `EmbeddingComparator`
2. Agrega mÃ©todos de reporte
3. Integra con `generate_reports()`

## ğŸ› SoluciÃ³n de Problemas

### Error: "No module named 'openai'"
```bash
uv run python emb_test.py  # Usar entorno virtual
```

### Error: "Directorio de datos no encontrado"
```bash
python data_loader.py  # Crear datos de ejemplo
```

### Error: "Archivo de work orders no encontrado"
Verifica que `data/work_orders.json` existe y es vÃ¡lido.

## ğŸ“ Soporte

Para problemas o preguntas:
1. Revisa los ejemplos en `example_usage.py`
2. Verifica la configuraciÃ³n en `data/config.json`
3. Consulta los reportes generados para debugging

---

**Â¡Disfruta comparando embeddings! ğŸš€**
